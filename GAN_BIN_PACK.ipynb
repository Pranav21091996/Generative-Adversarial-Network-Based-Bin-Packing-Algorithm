{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.contrib.slim as slim\n",
    "import os\n",
    "import scipy.misc\n",
    "import scipy\n",
    "from glob import glob\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './DataSet'\n",
    "data_files = glob(os.path.join(data_dir, 'Bin*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrelu(x, leak=0.2, name=\"lrelu\"):\n",
    "     with tf.variable_scope(name):\n",
    "            f1 = 0.5 * (1 + leak)\n",
    "            f2 = 0.5 * (1 - leak)\n",
    "            return f1 * x + f2 * abs(x)\n",
    "def save_images(images, size, image_path):\n",
    "    return imsave(inverse_transform(images), size, image_path)\n",
    "\n",
    "def imsave(images, size, path):\n",
    "    return scipy.misc.imsave(path, merge(images, size))\n",
    "\n",
    "def inverse_transform(images):\n",
    "    return (images+1.)/2.\n",
    "\n",
    "def merge(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    img = np.zeros((h * size[0], w * size[1]))\n",
    "\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w] = image\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z):\n",
    "    \n",
    "    zP = slim.fully_connected(z,2*2*512,normalizer_fn=slim.batch_norm,\\\n",
    "        activation_fn=tf.nn.relu,scope='g_project',weights_initializer=initializer)\n",
    "    zCon = tf.reshape(zP,[-1,2,2,256])\n",
    "    \n",
    "    gen1 = slim.convolution2d_transpose(\\\n",
    "        zCon,num_outputs=256,kernel_size=[5,5],stride=[2,2],\\\n",
    "        padding=\"SAME\",normalizer_fn=slim.batch_norm,\\\n",
    "        activation_fn=tf.nn.relu,scope='g_conv1', weights_initializer=initializer)\n",
    "    \n",
    "    gen2 = slim.convolution2d_transpose(\\\n",
    "        gen1,num_outputs=128,kernel_size=[5,5],stride=[2,2],\\\n",
    "        padding=\"SAME\",normalizer_fn=slim.batch_norm,\\\n",
    "        activation_fn=tf.nn.relu,scope='g_conv2', weights_initializer=initializer)\n",
    "    \n",
    "    gen3 = slim.convolution2d_transpose(\\\n",
    "        gen2,num_outputs=64,kernel_size=[5,5],stride=[2,2],\\\n",
    "        padding=\"SAME\",normalizer_fn=slim.batch_norm,\\\n",
    "        activation_fn=tf.nn.relu,scope='g_conv3', weights_initializer=initializer)\n",
    "\n",
    "    gen4 = slim.convolution2d_transpose(\\\n",
    "        gen3,num_outputs=32,kernel_size=[5,5],stride=[2,2],\\\n",
    "        padding=\"SAME\",normalizer_fn=slim.batch_norm,\\\n",
    "        activation_fn=tf.nn.relu,scope='g_conv4', weights_initializer=initializer)\n",
    "    \n",
    "    gen5 = slim.convolution2d_transpose(\\\n",
    "        gen4,num_outputs=16,kernel_size=[5,5],stride=[2,2],\\\n",
    "        padding=\"SAME\",normalizer_fn=slim.batch_norm,\\\n",
    "        activation_fn=tf.nn.relu,scope='g_conv5', weights_initializer=initializer)\n",
    "    \n",
    "    gen6 = slim.convolution2d_transpose(\\\n",
    "        gen5,num_outputs=8,kernel_size=[5,5],stride=[2,2],\\\n",
    "        padding=\"SAME\",normalizer_fn=slim.batch_norm,\\\n",
    "        activation_fn=tf.nn.relu,scope='g_conv6', weights_initializer=initializer)                                        \n",
    "    \n",
    "    g_out = slim.convolution2d_transpose(\\\n",
    "        gen6,num_outputs=3,kernel_size=[5,5],padding=\"SAME\",\\\n",
    "        biases_initializer=None,activation_fn=tf.nn.tanh,\\\n",
    "        scope='g_out', weights_initializer=initializer)\n",
    "    \n",
    "    return g_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(bottom, reuse=False):\n",
    "    \n",
    "    dis1 = slim.convolution2d(bottom,16,[5,5],stride=[2,2],padding=\"SAME\",\\\n",
    "        biases_initializer=None,activation_fn=lrelu,\\\n",
    "        reuse=reuse,scope='d_conv1',weights_initializer=initializer)\n",
    "    \n",
    "    dis2 = slim.convolution2d(dis1,32,[5,5],stride=[2,2],padding=\"SAME\",\\\n",
    "        normalizer_fn=slim.batch_norm,activation_fn=lrelu,\\\n",
    "        reuse=reuse,scope='d_conv2', weights_initializer=initializer)\n",
    "    \n",
    "    dis3 = slim.convolution2d(dis2,64,[5,5],stride=[2,2],padding=\"SAME\",\\\n",
    "        normalizer_fn=slim.batch_norm,activation_fn=lrelu,\\\n",
    "        reuse=reuse,scope='d_conv3',weights_initializer=initializer)\n",
    "    \n",
    "    dis4 = slim.convolution2d(dis3,128,[5,5],stride=[2,2],padding=\"SAME\",\\\n",
    "        normalizer_fn=slim.batch_norm,activation_fn=lrelu,\\\n",
    "        reuse=reuse,scope='d_conv4',weights_initializer=initializer)\n",
    "    \n",
    "    dis5 = slim.convolution2d(dis4,256,[5,5],stride=[2,2],padding=\"SAME\",\\\n",
    "        normalizer_fn=slim.batch_norm,activation_fn=lrelu,\\\n",
    "        reuse=reuse,scope='d_conv5',weights_initializer=initializer)\n",
    "    \n",
    "    d_out = slim.fully_connected(slim.flatten(dis5),1,activation_fn=tf.nn.sigmoid,\\\n",
    "        reuse=reuse,scope='d_out', weights_initializer=initializer)\n",
    "    \n",
    "    return d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "z_size = 100 #Size of z vector used for generator.\n",
    "\n",
    "#This initializaer is used to initialize all the weights of the network.\n",
    "initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "\n",
    "#These two placeholders are used for input into the generator and discriminator, respectively.\n",
    "z_in = tf.placeholder(shape=[None,z_size],dtype=tf.float32) #Random vector\n",
    "real_in = tf.placeholder(shape=[None,256,256,3],dtype=tf.float32) #Real images\n",
    "\n",
    "Gz = generator(z_in) #Generates images from random z vectors\n",
    "Dx = discriminator(real_in) #Produces probabilities for real images\n",
    "Dg = discriminator(Gz,reuse=True) #Produces probabilities for generator images\n",
    "\n",
    "#These functions together define the optimization objective of the GAN.\n",
    "d_loss = -tf.reduce_mean(tf.log(Dx) + tf.log(1.-Dg)) #This optimizes the discriminator.\n",
    "g_loss = -tf.reduce_mean(tf.log(Dg)) #This optimizes the generator.\n",
    "\n",
    "tvars = tf.trainable_variables()\n",
    "\n",
    "#The below code is responsible for applying gradient descent to update the GAN.\n",
    "trainerD = tf.train.AdamOptimizer(learning_rate=0.0002,beta1=0.5)\n",
    "trainerG = tf.train.AdamOptimizer(learning_rate=0.0002,beta1=0.5)\n",
    "d_grads = trainerD.compute_gradients(d_loss,tvars[9:]) #Only update the weights for the discriminator network.\n",
    "g_grads = trainerG.compute_gradients(g_loss,tvars[0:9]) #Only update the weights for the generator network.\n",
    "\n",
    "update_D = trainerD.apply_gradients(d_grads)\n",
    "update_G = trainerG.apply_gradients(g_grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 #Size of image batch to apply at each iteration.\n",
    "iterations = 500000 #Total number of iterations to use.\n",
    "sample_directory = './figs' #Directory to save sample images from generator in.\n",
    "model_directory = './models' #Directory to save trained model to.\n",
    "data_batch = np.array(\n",
    "        [np.array((Image.open(sample_file))) for sample_file in data_files]).astype(np.float32)\n",
    "init = tf.initialize_all_variables()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:  \n",
    "    sess.run(init)\n",
    "    for i in range(iterations):\n",
    "        zs = np.random.uniform(-1.0,1.0,size=[batch_size,z_size]).astype(np.float32) #Generate a random z batch\n",
    "        xs = tf.train.shuffle_batch(data_batch, batch_size)\n",
    "        _,dLoss = sess.run([update_D,d_loss],feed_dict={z_in:zs,real_in:xs}) #Update the discriminator\n",
    "        _,gLoss = sess.run([update_G,g_loss],feed_dict={z_in:zs}) #Update the generator, twice for good measure.\n",
    "        _,gLoss = sess.run([update_G,g_loss],feed_dict={z_in:zs})\n",
    "        if i % 10 == 0:\n",
    "            print (\"Gen Loss: \" + str(gLoss) + \" Disc Loss: \" + str(dLoss))\n",
    "            z2 = np.random.uniform(-1.0,1.0,size=[batch_size,z_size]).astype(np.float32) #Generate another z batch\n",
    "            newZ = sess.run(Gz,feed_dict={z_in:z2}) #Use new z to get sample images from generator.\n",
    "            if not os.path.exists(sample_directory):\n",
    "                os.makedirs(sample_directory)\n",
    "            #Save sample generator images for viewing training progress.\n",
    "            save_images(newZ,sample_directory+'/fig'+str(i)+'.jpg')\n",
    "        if i % 1000 == 0 and i != 0:\n",
    "            if not os.path.exists(model_directory):\n",
    "                os.makedirs(model_directory)\n",
    "            saver.save(sess,model_directory+'/model-'+str(i)+'.cptk')\n",
    "            print (\"Saved Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
